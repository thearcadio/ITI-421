{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfJ8O/xlMsB5F5hFpblne/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thearcadio/ITI-421/blob/main/Classification_in_Python_Sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wtoZg7ZiQZO4"
      },
      "outputs": [],
      "source": [
        "# you will just load your own data later and can skip this step\n",
        "# for the sake of having an example to see I'm using an already available data set\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "# you will need to import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Above I imported the data, this is actually loading it in\n",
        "wine = load_wine() # import your data set at this step"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(wine)) # as you can see, the type of this dat set is Bunch\n",
        "# you may find it easier to to work with Bunches than Data Frames, check out this forum:\n",
        "# https://stackoverflow.com/questions/59946315/how-can-we-convert-a-dataframe-in-to-bunch-data-type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfAJDonFRVN6",
        "outputId": "ae3055fb-7f1d-4e23-88b6-35eec3702d90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we are importing what we need to split our data... more below\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# we talked about this earlier in the semester, we split our data for training and testing our model\n",
        "# the example below is saying to hold 20% for a test, this is a common value used, it make make\n",
        "# sense for you to use more or less, I can answer questions specific to your application :)\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2)"
      ],
      "metadata": {
        "id": "h2KYMIeYSsEr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another thing we discussed in class was either scaling or normalizing values to ensure\n",
        "# that different measurements are appropriately weighted. This isn't so straightforward\n",
        "# in SPSS, but in Python it is just a matter of a few lines of code\n",
        "\n",
        "# We are importing the needed package\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Actually creating the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# We fit the scalar to the testing and training seperate so that the values in one\n",
        "# don't influence the others\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "CkKHHx0QTYBf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# While there are many classifiers available in the SciKit Learn package I'd say\n",
        "# the most useful for you all would be the logistic regression one\n",
        "# If you see others that interest you here: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
        "# I'd be happy to schedule office hours to walk you through them in detail\n",
        "\n",
        "# Importing the packages we need\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Creating our actual classifier with our training data\n",
        "classifier = LogisticRegression().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "YBlyBgu6UFHj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What good is a model if we can't easily assess it? To do this, we will use the\n",
        "# the metrics package included in SciKit Learn\n",
        "from sklearn import metrics\n",
        "\n",
        "# We are now using the testing data we held out before...\n",
        "# It is fed into our classifier and that classifier will make a prediction\n",
        "# as to what class each row belongs to\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "# One way we can assess our model is a confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, predictions)\n",
        "print(cm)\n",
        "\n",
        "# The values in a confusion matrix that lie along the diagonal represent the \n",
        "# correct classificaitons... The more of the values that lie on the diagnol, the\n",
        "# more your model correctly classified"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVX8mESLVen3",
        "outputId": "b9291fe0-2d73-495d-e0e4-31d9893838f3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11  0  0]\n",
            " [ 1 12  0]\n",
            " [ 0  0 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This was my model's output\n",
        "# [[11  0  0]\n",
        "#  [ 1 12  0]\n",
        "# [ 0  0 12]]\n",
        "# The great thing about a confusion matrix is that it is easy to interpret\n",
        "# The number of classes you have determines the size of the matrix, for example\n",
        "# if I were to build the classifier I mentioned in class, the one to predict \n",
        "# a student's academic class at Rutgers, they'd be one of 4 classes: FR, SO, JR, SR\n",
        "# Thus our matrix would be 4 x 4.\n",
        "# You can put this table into you report pretty easily too, it just is something that\n",
        "# is a quick/consise way to summarize how \"good\" your model is"
      ],
      "metadata": {
        "id": "ZVQGivUCWt_S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another set of available metrics are accuracy, precision, recall, and f1\n",
        "accuracy = metrics.accuracy_score(y_test, predictions) # accuracy\n",
        "precision = metrics.precision_score(y_test, predictions, average = 'macro') # precision\n",
        "recall = metrics.recall_score(y_test, predictions, average = 'macro') # recall\n",
        "f1 = metrics.f1_score(y_test, predictions, average='macro') # f1\n",
        "\n",
        "print(\"Accuracy = \" + str(accuracy))\n",
        "print(\"Precision = \" + str(precision))\n",
        "print(\"Recall = \" + str(recall))\n",
        "print(\"F1-score = \" + str(f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsHlwKcfXiCA",
        "outputId": "f87c3697-e86e-42ca-aa76-44188b9d879e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 0.9722222222222222\n",
            "Precision = 0.9722222222222222\n",
            "Recall = 0.9743589743589745\n",
            "F1-score = 0.9721739130434783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The results I got were as follows\n",
        "# Accuracy = 0.9722222222222222\n",
        "# Precision = 0.9722222222222222\n",
        "# Recall = 0.9743589743589745\n",
        "# F1-score = 0.9721739130434783\n",
        "# Based on how SciKit built your model, you may get different results\n",
        "# A brief explanation of each can be found here: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9\n",
        "# Which is the most appropriate or expected is domain specific, so for your cases\n",
        "# You can just report all...\n",
        "#\n",
        "# For some extra context, the article I linked goes into great detail, but again,\n",
        "# the domain matters... when you're trying to avoid missing a \"positive\" result\n",
        "# which is especially true in the medical field, then recall, which is more geared\n",
        "# to address this, may be appropriate.\n",
        "#\n",
        "# Again, for the scope of this project and for how minimal the code is, you can\n",
        "# just report all, but I wanted to at least give you some context on each to \n",
        "# read if you want it\n",
        "#\n",
        "# Last, but not least, I want to reiterate that logistic regression is just one approach\n",
        "# to building a classifier, and perhaps one of the easiest to implement and then\n",
        "# interpret the results. It isn't the end all/automatic best choice always. The\n",
        "# intent is just to teach you all when you'd use classification versus regression."
      ],
      "metadata": {
        "id": "TCKGGplLX4A7"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}